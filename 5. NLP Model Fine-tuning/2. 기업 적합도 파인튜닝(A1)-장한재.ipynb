{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"w5b09EZNEsY4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1725341856580,"user_tz":-540,"elapsed":51926,"user":{"displayName":"백현지","userId":"02510457579208942463"}},"outputId":"91d9a298-7d62-4b37-ed51-a96b7ab527d2"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.42.4)\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.4.0+cu121)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.15.4)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.23.5)\n","Requirement already satisfied: numpy<2.0,>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.4)\n","Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.5)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.8)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.7.4)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n","Collecting gluonnlp\n","  Downloading gluonnlp-0.10.0.tar.gz (344 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m344.5/344.5 kB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.1.4)\n","Collecting pandas\n","  Downloading pandas-2.2.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (19 kB)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.5)\n","Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from gluonnlp) (1.26.4)\n","Requirement already satisfied: cython in /usr/local/lib/python3.10/dist-packages (from gluonnlp) (3.0.11)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gluonnlp) (24.1)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n","Downloading pandas-2.2.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.0/13.0 MB\u001b[0m \u001b[31m117.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hBuilding wheels for collected packages: gluonnlp\n","  Building wheel for gluonnlp (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for gluonnlp: filename=gluonnlp-0.10.0-cp310-cp310-linux_x86_64.whl size=661659 sha256=caee3433dfa9acbdbd35bccf31563c08be3b4ad09605256e73f410da00f9879f\n","  Stored in directory: /root/.cache/pip/wheels/1a/1e/0d/99f55911d90f2b95b9f7c176d5813ef3622894a4b30fde6bd3\n","Successfully built gluonnlp\n","Installing collected packages: gluonnlp, pandas\n","  Attempting uninstall: pandas\n","    Found existing installation: pandas 2.1.4\n","    Uninstalling pandas-2.1.4:\n","      Successfully uninstalled pandas-2.1.4\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","cudf-cu12 24.4.1 requires pandas<2.2.2dev0,>=2.0, but you have pandas 2.2.2 which is incompatible.\n","google-colab 1.0.0 requires pandas==2.1.4, but you have pandas 2.2.2 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed gluonnlp-0.10.0 pandas-2.2.2\n","Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.32.1)\n","Collecting accelerate\n","  Downloading accelerate-0.34.0-py3-none-any.whl.metadata (19 kB)\n","Requirement already satisfied: numpy<3.0.0,>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.26.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (24.1)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.2)\n","Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.4.0+cu121)\n","Requirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.23.5)\n","Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.4)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (3.15.4)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (2024.6.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (2.32.3)\n","Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (4.66.5)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (4.12.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.13.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.4)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.8)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2024.7.4)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n","Downloading accelerate-0.34.0-py3-none-any.whl (324 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m324.3/324.3 kB\u001b[0m \u001b[31m22.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: accelerate\n","  Attempting uninstall: accelerate\n","    Found existing installation: accelerate 0.32.1\n","    Uninstalling accelerate-0.32.1:\n","      Successfully uninstalled accelerate-0.32.1\n","Successfully installed accelerate-0.34.0\n","Mounted at /content/drive\n"]}],"source":["# 필요한 라이브러리 설치\n","!pip install transformers torch\n","!pip install --upgrade gluonnlp pandas tqdm\n","!pip install accelerate -U\n","\n","# 라이브러리 임포트\n","import pandas as pd\n","import csv\n","from sklearn.model_selection import train_test_split\n","import torch\n","from torch.utils.data import Dataset, DataLoader, TensorDataset, RandomSampler, SequentialSampler, random_split\n","import torch.nn as nn\n","import torch.optim as optim\n","from transformers import AutoModel, AutoTokenizer, Trainer, TrainingArguments\n","from transformers import ElectraModel, ElectraTokenizer\n","import numpy as np\n","from tqdm.auto import tqdm\n","from google.colab import drive\n","import glob\n","import os\n","from torch.optim import AdamW\n","from sklearn.metrics import accuracy_score, mean_squared_error\n","\n","# Google Drive 마운트\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"T01054dtI1rJ"},"source":["#훈련 및 평가"]},{"cell_type":"code","source":["import os\n","import torch\n","import pandas as pd\n","from transformers import ElectraTokenizer, ElectraModel, AdamW\n","from torch.utils.data import DataLoader, TensorDataset, random_split, RandomSampler, SequentialSampler\n","from sklearn.metrics import mean_squared_error\n","from tqdm import tqdm\n","import torch.nn as nn\n","\n","# KoElectra 토크나이저와 모델 불러오기\n","tokenizer = ElectraTokenizer.from_pretrained(\"monologg/koelectra-base-discriminator\")\n","\n","# 회귀를 위한 모델 정의\n","class ElectraForCompanyRegression(nn.Module):\n","    def __init__(self, model_name):\n","        super(ElectraForCompanyRegression, self).__init__()\n","        self.electra = ElectraModel.from_pretrained(model_name)\n","        self.dropout = nn.Dropout(0.1)\n","        self.regressor = nn.Linear(self.electra.config.hidden_size + 768, 1)\n","\n","    def forward(self, input_ids, attention_mask, company_embeddings):\n","        outputs = self.electra(input_ids=input_ids, attention_mask=attention_mask)\n","        pooled_output = outputs.last_hidden_state[:, 0, :]  # [batch_size, hidden_size]\n","        combined_output = torch.cat((pooled_output, company_embeddings), dim=1)\n","        combined_output = self.dropout(combined_output)\n","        logits = self.regressor(combined_output)\n","        return logits\n","\n","# 기업명 임베딩 생성\n","def get_company_embedding(company_name, tokenizer, model):\n","    inputs = tokenizer(company_name, return_tensors=\"pt\").to('cuda')  # Ensure input is on GPU\n","    with torch.no_grad():\n","        outputs = model.electra(**inputs)\n","    company_embedding = outputs.last_hidden_state[:, 0, :]\n","    return company_embedding\n","\n","def preprocess_with_company(data, tokenizer, model, max_len=256):\n","    texts = data[\"full_text\"].astype(str).tolist()\n","    labels = data[\"evaluation_1\"].fillna(0).astype(float).tolist()\n","    company_names = data[\"기업명\"].astype(str).tolist()\n","\n","    inputs = tokenizer(\n","        texts,\n","        max_length=max_len,\n","        padding=True,\n","        truncation=True,\n","        return_tensors=\"pt\"\n","    ).to('cuda')  # Ensure inputs are on GPU\n","\n","    labels = torch.tensor(labels, dtype=torch.float).to('cuda')  # Move labels to GPU\n","\n","    # 기업명 임베딩 생성 및 병합\n","    company_embeddings = []\n","    for company_name in tqdm(company_names, desc=\"Generating company embeddings\"):\n","        embedding = get_company_embedding(company_name, tokenizer, model).to('cuda')\n","        company_embeddings.append(embedding)\n","    company_embeddings = torch.cat(company_embeddings, dim=0)\n","\n","    return inputs, labels, company_embeddings\n","\n","# 데이터셋 로드\n","file_path = '/content/drive/MyDrive/Kwargs/적합성/anonymized_data.csv'\n","data = pd.read_csv(file_path)\n","\n","# 모델 초기화\n","model_name = \"monologg/koelectra-base-discriminator\"\n","model = ElectraForCompanyRegression(model_name).to('cuda')  # Ensure model is on GPU\n","\n","# 데이터 전처리\n","print(\"Preprocessing data...\")\n","inputs, labels, company_embeddings = preprocess_with_company(data, tokenizer, model)\n","\n","# TensorDataset 생성\n","dataset = TensorDataset(inputs['input_ids'], inputs['attention_mask'], company_embeddings, labels)\n","\n","# 데이터셋 분할\n","train_size = int(0.8 * len(dataset))\n","val_size = len(dataset) - train_size\n","\n","train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n","\n","# 데이터 로더 생성\n","train_dataloader = DataLoader(train_dataset, sampler=RandomSampler(train_dataset), batch_size=16)\n","val_dataloader = DataLoader(val_dataset, sampler=SequentialSampler(val_dataset), batch_size=16)\n","\n","optimizer = AdamW(model.parameters(), lr=5e-5)\n","\n","# 모든 텐서를 GPU로 이동\n","def to_device(batch, device):\n","    return [x.to(device) for x in batch]\n","\n","# 훈련 함수\n","def train(model, train_dataloader, optimizer, device):\n","    model.train()\n","    total_loss = 0\n","    for batch in tqdm(train_dataloader, desc=\"Training\"):\n","        batch = to_device(batch, device)\n","        input_ids, attention_mask, company_embeddings, labels = batch\n","        optimizer.zero_grad()\n","        logits = model(input_ids, attention_mask, company_embeddings).squeeze()\n","        loss = nn.MSELoss()(logits, labels)\n","        loss.backward()\n","        optimizer.step()\n","        total_loss += loss.item()\n","    return total_loss / len(train_dataloader)\n","\n","# 평가 함수\n","def evaluate(model, val_dataloader, device):\n","    model.eval()\n","    total_loss = 0\n","    all_labels = []\n","    all_preds = []\n","    with torch.no_grad():\n","        for batch in tqdm(val_dataloader, desc=\"Evaluating\"):\n","            batch = to_device(batch, device)\n","            input_ids, attention_mask, company_embeddings, labels = batch\n","            logits = model(input_ids, attention_mask, company_embeddings).squeeze()\n","            loss = nn.MSELoss()(logits, labels)\n","            total_loss += loss.item()\n","            all_labels.extend(labels.cpu().numpy())\n","            all_preds.extend(logits.cpu().numpy())\n","    mse = mean_squared_error(all_labels, all_preds)\n","    return total_loss / len(val_dataloader), mse\n","\n","# 훈련 및 평가 루프\n","num_epochs = 3\n","for epoch in range(num_epochs):\n","    print(f\"Epoch {epoch + 1}/{num_epochs}\")\n","    train_loss = train(model, train_dataloader, optimizer, 'cuda')\n","    val_loss, val_mse = evaluate(model, val_dataloader, 'cuda')\n","    print(f\"Training Loss: {train_loss:.4f}\")\n","    print(f\"Validation Loss: {val_loss:.4f}\")\n","    print(f\"Validation MSE: {val_mse:.4f}\")\n","\n","    # 모델 저장\n","    epoch_output_dir = f\"/content/drive/MyDrive/Kwargs/적합성/모델_epoch_{epoch + 1}\"\n","    if not os.path.exists(epoch_output_dir):\n","        os.makedirs(epoch_output_dir)\n","\n","    # 모델 가중치 저장\n","    torch.save(model.state_dict(), os.path.join(epoch_output_dir, \"model.pt\"))\n","\n","    # 토크나이저 저장\n","    tokenizer.save_pretrained(epoch_output_dir)\n","    print(f\"Model and tokenizer saved to {epoch_output_dir} at Epoch {epoch + 1}\")\n"],"metadata":{"id":"T3gnSPvx0Jks","colab":{"base_uri":"https://localhost:8080/"},"outputId":"2c0a97c4-4027-4166-bbc2-e398dc5e364f"},"execution_count":null,"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Preprocessing data...\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Generating company embeddings: 100%|██████████| 85771/85771 [14:00<00:00, 102.00it/s]\n","/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch 1/3\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Training: 100%|██████████| 4289/4289 [12:02<00:00,  5.94it/s]\n","Evaluating: 100%|██████████| 1073/1073 [00:57<00:00, 18.56it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Training Loss: 0.0868\n","Validation Loss: 0.0785\n","Validation MSE: 0.0785\n","Model and tokenizer saved to /content/drive/MyDrive/Kwargs/적합성/모델_epoch_1 at Epoch 1\n","Epoch 2/3\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Training: 100%|██████████| 4289/4289 [12:02<00:00,  5.94it/s]\n","Evaluating: 100%|██████████| 1073/1073 [00:57<00:00, 18.55it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Training Loss: 0.1168\n","Validation Loss: 0.1231\n","Validation MSE: 0.1231\n","Model and tokenizer saved to /content/drive/MyDrive/Kwargs/적합성/모델_epoch_2 at Epoch 2\n","Epoch 3/3\n"]},{"output_type":"stream","name":"stderr","text":["Training: 100%|██████████| 4289/4289 [12:02<00:00,  5.94it/s]\n","Evaluating:  94%|█████████▍| 1006/1073 [00:54<00:03, 18.51it/s]"]}]},{"cell_type":"markdown","source":["# 완성된 모델로 로우데이터 평가"],"metadata":{"id":"ORaNlVxZgUlM"}},{"cell_type":"code","source":["import torch\n","import pandas as pd\n","from transformers import ElectraTokenizer\n","from torch.utils.data import DataLoader, TensorDataset, SequentialSampler\n","from tqdm.auto import tqdm\n","\n","# 모델 정의 클래스 가져오기 (이미 위에 정의된 것으로 가정)\n","class ElectraForCompanyRegression(nn.Module):\n","    def __init__(self, model_name):\n","        super(ElectraForCompanyRegression, self).__init__()\n","        self.electra = ElectraModel.from_pretrained(model_name)\n","        self.dropout = nn.Dropout(0.1)\n","        self.regressor = nn.Linear(self.electra.config.hidden_size + 768, 1)\n","\n","    def forward(self, input_ids, attention_mask, company_embeddings):\n","        outputs = self.electra(input_ids=input_ids, attention_mask=attention_mask)\n","        pooled_output = outputs.last_hidden_state[:, 0, :]  # [batch_size, hidden_size]\n","        combined_output = torch.cat((pooled_output, company_embeddings), dim=1)\n","        combined_output = self.dropout(combined_output)\n","        logits = self.regressor(combined_output)\n","        return logits\n","\n","# 모델과 토크나이저 로드\n","model_path = '/content/drive/MyDrive/Kwargs/적합성/모델_epoch_1'\n","model_name = \"monologg/koelectra-base-discriminator\"\n","model = ElectraForCompanyRegression(model_name)\n","model.load_state_dict(torch.load(f\"{model_path}/model.pt\"))\n","model.to('cuda')\n","model.eval()\n","\n","tokenizer = ElectraTokenizer.from_pretrained(model_path)\n","\n","# 기업명 임베딩 생성\n","def get_company_embedding(company_name, tokenizer, model):\n","    inputs = tokenizer(company_name, return_tensors=\"pt\").to('cuda')  # Ensure input is on GPU\n","    with torch.no_grad():\n","        outputs = model.electra(**inputs)\n","    company_embedding = outputs.last_hidden_state[:, 0, :]\n","    return company_embedding\n","\n","# 새로운 데이터 전처리\n","def preprocess_with_company(data, tokenizer, model, max_len=256):\n","    texts = data[\"full_text\"].astype(str).tolist()\n","    company_names = data[\"기업명\"].astype(str).tolist()\n","\n","    inputs = tokenizer(\n","        texts,\n","        max_length=max_len,\n","        padding=True,\n","        truncation=True,\n","        return_tensors=\"pt\"\n","    ).to('cuda')  # Ensure inputs are on GPU\n","\n","    # 기업명 임베딩 생성 및 병합\n","    company_embeddings = []\n","    for company_name in tqdm(company_names, desc=\"Generating company embeddings\"):\n","        embedding = get_company_embedding(company_name, tokenizer, model).to('cuda')\n","        company_embeddings.append(embedding)\n","    company_embeddings = torch.cat(company_embeddings, dim=0)\n","\n","    return inputs, company_embeddings\n","\n","# 새로운 CSV 데이터 로드\n","file_path = '/content/drive/MyDrive/Kwargs/뉴스 크롤링/csv/LG에너지솔루션_news_data.csv'  # 예측할 CSV 파일 경로\n","data = pd.read_csv(file_path)\n","\n","# 데이터 전처리\n","print(\"Preprocessing data...\")\n","inputs, company_embeddings = preprocess_with_company(data, tokenizer, model)\n","\n","# TensorDataset 생성\n","dataset = TensorDataset(inputs['input_ids'], inputs['attention_mask'], company_embeddings)\n","\n","# 데이터 로더 생성\n","dataloader = DataLoader(dataset, sampler=SequentialSampler(dataset), batch_size=16)\n","\n","# 예측 함수\n","def predict(model, dataloader, device):\n","    model.eval()\n","    all_preds = []\n","    with torch.no_grad():\n","        for batch in tqdm(dataloader, desc=\"Predicting\"):\n","            batch = [x.to(device) for x in batch]\n","            input_ids, attention_mask, company_embeddings = batch\n","            logits = model(input_ids, attention_mask, company_embeddings).squeeze()\n","            all_preds.extend(logits.cpu().numpy())\n","    return all_preds\n","\n","# 모델을 사용하여 예측 수행\n","print(\"Predicting labels for new data...\")\n","predictions = predict(model, dataloader, 'cuda')\n","\n","# 예측 결과를 원래 데이터와 함께 저장\n","data[\"evaluation_1\"] = predictions\n","output_path = '/content/drive/MyDrive/Kwargs/적합성/company_related_LG에너지솔루션.csv'\n","data.to_csv(output_path, index=False)\n","\n","print(f\"Predicted results saved to {output_path}\")\n"],"metadata":{"id":"NL_Id0JEceNN","colab":{"base_uri":"https://localhost:8080/","height":836,"referenced_widgets":["eedb8c72a99a49c9bd197fc4ef513ace","f82553869a3e4e7887599a29cc9e8756","ef585876179644a8ab7746f6b5dc354e","68b31a7df7aa4ba2b0f284bd49cf866e","45a5abcb2636477a899e7b6935dd43fe","80b854e09fbe4fef9c8d4b06c0be4955","7d1a084aa305476d8fc3bb0e5ee8ac06","8870100023cb4242b01382e92337a862","bddd4c2225804f42827f37bcde29b678","302b008920cc4715903affa016ace231","1e943e1a23fc43eab0c392b83e040ef2","bd86ac5992154335954d3fd10468c2db","1330ea8051e942319376cb5b1ffe2e48","cbf5028f0f114d409ba582defb64b804","d30624acec484ea682a36aded4732755","35be482f056543deb347e10eb0e8325b","2a1b14fab83d44cf93e4fae2996d1485","e03bd6c0afd1428a9755e8c86085caa6","61e51538e8b846bb986728591f1adb70","dca69bf077f74a26b1c149eaab514270","d04c948f54cf442b9d68862f34504c25","4b16cac5e77b426e99b4b87ee62298e1"]},"executionInfo":{"status":"error","timestamp":1725342199006,"user_tz":-540,"elapsed":56933,"user":{"displayName":"백현지","userId":"02510457579208942463"}},"outputId":"f0afc960-7007-4f75-adee-ebe630ba7f95"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/467 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eedb8c72a99a49c9bd197fc4ef513ace"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["pytorch_model.bin:   0%|          | 0.00/443M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bd86ac5992154335954d3fd10468c2db"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["<ipython-input-2-b1f562a8c68c>:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  model.load_state_dict(torch.load(f\"{model_path}/model.pt\"))\n"]},{"output_type":"stream","name":"stdout","text":["Preprocessing data...\n"]},{"output_type":"error","ename":"KeyError","evalue":"'full_text'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3805\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3806\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n","\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n","\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n","\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: 'full_text'","\nThe above exception was the direct cause of the following exception:\n","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-b1f562a8c68c>\u001b[0m in \u001b[0;36m<cell line: 69>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;31m# 데이터 전처리\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Preprocessing data...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompany_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess_with_company\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;31m# TensorDataset 생성\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-2-b1f562a8c68c>\u001b[0m in \u001b[0;36mpreprocess_with_company\u001b[0;34m(data, tokenizer, model, max_len)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;31m# 새로운 데이터 전처리\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpreprocess_with_company\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m     \u001b[0mtexts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"full_text\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m     \u001b[0mcompany_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"기업명\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4101\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4102\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4103\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4104\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3810\u001b[0m             ):\n\u001b[1;32m   3811\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mInvalidIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3812\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3813\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3814\u001b[0m             \u001b[0;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: 'full_text'"]}]},{"cell_type":"code","source":[],"metadata":{"id":"HyfpqMaVZ8wC"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"machine_shape":"hm","provenance":[],"gpuType":"A100","authorship_tag":"ABX9TyOPMJJwKYDH62NpEC99HCEI"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"eedb8c72a99a49c9bd197fc4ef513ace":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f82553869a3e4e7887599a29cc9e8756","IPY_MODEL_ef585876179644a8ab7746f6b5dc354e","IPY_MODEL_68b31a7df7aa4ba2b0f284bd49cf866e"],"layout":"IPY_MODEL_45a5abcb2636477a899e7b6935dd43fe"}},"f82553869a3e4e7887599a29cc9e8756":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_80b854e09fbe4fef9c8d4b06c0be4955","placeholder":"​","style":"IPY_MODEL_7d1a084aa305476d8fc3bb0e5ee8ac06","value":"config.json: 100%"}},"ef585876179644a8ab7746f6b5dc354e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8870100023cb4242b01382e92337a862","max":467,"min":0,"orientation":"horizontal","style":"IPY_MODEL_bddd4c2225804f42827f37bcde29b678","value":467}},"68b31a7df7aa4ba2b0f284bd49cf866e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_302b008920cc4715903affa016ace231","placeholder":"​","style":"IPY_MODEL_1e943e1a23fc43eab0c392b83e040ef2","value":" 467/467 [00:00&lt;00:00, 36.9kB/s]"}},"45a5abcb2636477a899e7b6935dd43fe":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"80b854e09fbe4fef9c8d4b06c0be4955":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7d1a084aa305476d8fc3bb0e5ee8ac06":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8870100023cb4242b01382e92337a862":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bddd4c2225804f42827f37bcde29b678":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"302b008920cc4715903affa016ace231":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1e943e1a23fc43eab0c392b83e040ef2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bd86ac5992154335954d3fd10468c2db":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_1330ea8051e942319376cb5b1ffe2e48","IPY_MODEL_cbf5028f0f114d409ba582defb64b804","IPY_MODEL_d30624acec484ea682a36aded4732755"],"layout":"IPY_MODEL_35be482f056543deb347e10eb0e8325b"}},"1330ea8051e942319376cb5b1ffe2e48":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2a1b14fab83d44cf93e4fae2996d1485","placeholder":"​","style":"IPY_MODEL_e03bd6c0afd1428a9755e8c86085caa6","value":"pytorch_model.bin: 100%"}},"cbf5028f0f114d409ba582defb64b804":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_61e51538e8b846bb986728591f1adb70","max":443135628,"min":0,"orientation":"horizontal","style":"IPY_MODEL_dca69bf077f74a26b1c149eaab514270","value":443135628}},"d30624acec484ea682a36aded4732755":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d04c948f54cf442b9d68862f34504c25","placeholder":"​","style":"IPY_MODEL_4b16cac5e77b426e99b4b87ee62298e1","value":" 443M/443M [00:32&lt;00:00, 11.9MB/s]"}},"35be482f056543deb347e10eb0e8325b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2a1b14fab83d44cf93e4fae2996d1485":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e03bd6c0afd1428a9755e8c86085caa6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"61e51538e8b846bb986728591f1adb70":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dca69bf077f74a26b1c149eaab514270":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d04c948f54cf442b9d68862f34504c25":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4b16cac5e77b426e99b4b87ee62298e1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}